setwd("D:/Workplace/Statistical_Analysis_R/ch03")
library(prob)
install.packages("prob")
library(prob)
tosscoin(1)
rolldie(1)
urnsamples(1:3,size=2)
urnsamples(1:3,size=2,replace=T)
urnsamples(c(rep("R",3),rep("B",2)),size=2)
tosscoin(2,makespace=T)
x <- 0:2
px <- c(0.25,0.5,0.25)
(EX <- sum(x*px))
x*2
x*(1:4)
x*(1:6)
(VX <- sum(x^2*px)-EX^2)
n <- 6
p <- 1/3
x <- 0:n
(dbinom(2,size=n,prob=p))
(dbinom(4,size=n,prob=p))
(px <- dbinom(x,size=n,prob=p))
plot(x,px,type="s",xlab="성공 횟수(x)",ylab="확률(P[X=x])",
main="B(6,1/3)")
pbinom(2,size=n,prob=p)
pbinom(4,size=n,prob=p)
pbinom(4,size=n,prob=p) - pbinom(2,size=n,prob=p)
qbinom(0.1,size=n,prob=p)
qbinom(0.5,size=n,prob=p)
rbinom(10,size=n,prob=p)
px <- dbinom(x,size=n,prob=p)
(ex <- sum(x*px))
(ex2 <- sum(x^2*px))
(varx <- ex2-ex^2)
plot(x,px,type="h",xlab="성공 횟수(x)",ylab="확률(P[X=x])",
main="B(6,1/3)",col="blue")
plot(x,px,type="h",xlab="성공 횟수(x)",ylab="확률(P[X=x])",
main="B(6,1/3)",col="blue",lwd=10)
G1.test <- rnorm(1000,2,1) ; G2.test <- rnorm(1000,-2,1)
my.LDA <- function(n1,n2,test1,test2) {
## Make training data
n1 <- n1 ; n2 <- n2
n <- n1+n2
k <- 2
prior1 <- n1/n ; prior2 <- n2/n
G1.train <- rnorm(n1,2,1) ; G2.train <- rnorm(n2,-2,1)
mu1 <- mean(G1.train) ; mu2 <- mean(G2.train)
sigma2 <- sum((G1.train-mu1)^2+(G2.train-mu2)^2)/(n-k)
## Make test data
test <- c(test1,test2)
true.group <- c(rep("Group1",1000),rep("Group2",1000))
## Decision boundary of LDA when k=2
delta1 <- function(x) x*(mu1/sigma2)-(((mu1^2)/sigma2)/2)+log(prior1)
delta2 <- function(x) x*(mu2/sigma2)-(((mu2^2)/sigma2)/2)+log(prior2)
d1 <- delta1(test) ; d2 <- delta2(test)
boundary <- d1-d2
predict.group <- rep("Group1",2000)
predict.group[boundary < 0] <- "Group2"
## Drawing some graph
par(mfrow=c(1,2))
# Picture 1
x <- seq(-5,5,0.001)
y1 <- dnorm(x,2,1) ; y2 <- dnorm(x,-2,1)
plot(x,y1,main="Normal distributions for two groups",type="n",xlab="x",ylab="y")
lines(x,y1,col="hotpink",lwd=2,lty=1)
lines(x,y2,col="darkgreen",lwd=2,lty=1)
abline(v=0,lty=2,lwd=2)
# Picture 2
hist(G2.train,col="darkgreen",breaks=12,xlim=c(-5,5),prob=TRUE,main="",xlab="",ylab="")
par(new=TRUE)
hist(G1.train,col="hotpink",density=25,breaks=12,angle=45,xlim=c(-5,5),
prob=TRUE,main="Result of Linear Discriminant Analysis",
xlab="train",ylab="density",axes=FALSE)
abline(v=0,lty=2,lwd=2)
abline(v=((mu1+mu2)/2)+(sigma2/(mu1-mu2))*log(prior2/prior1),lty=1,lwd=2)
## Classification result
res <- table(predict.group,true.group)
miss <- mean(predict.group!=true.group) # Misclassificaion rate
cat("\n","**Confusion matrix**")
cat("\n","( When n1 =",n1,"and n2 =",n2,")","\n")
print(res)
cat("\n","Misclassification rate is",miss,".")
cat("\n","And LDA decision boundary estimated from the training data is",
((mu1+mu2)/2)+(sigma2/(mu1-mu2))*log(prior2/prior1),".")
}
## Checking result
my.LDA(20,20,G1.test,G2.test)
my.LDA(50,50,G1.test,G2.test)
my.LDA(100,100,G1.test,G2.test)
my.LDA(500,500,G1.test,G2.test)
my.LDA(1000,1000,G1.test,G2.test)
my.LDA(1500,1500,G1.test,G2.test)
my.LDA(2000,2000,G1.test,G2.test)
options(digits=3)
mu <- 170
sigma <- 6
ll <- mu - 3*sigma
ul <- mu + 3*sigma
x <- seq(ll,ul,by=0.01)
nd <- dnorm(x,mean=mu,sd=sigma)
plot(x,nd,type="l",xlab="x",ylab="P(X=x)",lwd=2,col="red")
par(mfrow=c(1,1))
plot(x,nd,type="l",xlab="x",ylab="P(X=x)",lwd=2,col="red")
options(digits=5)
set.seed(5)
smp <- rnorm(400,mean=mu,sd=sigma)
c(mean(smp),sd(smp))
hist(smp,prob=T,main="N(170,6^2)으로부터 추출한 표본의 분포(n=400)",
xlab="",ylab="",col="white",border="black")
lines(x,nd,lty=2)
options(digits=4)
mu <- 0
sigma <- 1
(p0.05 <- qnorm(0.05,mean=mu,sd=sigma))
(p0.025 <- qnorm(0.025,mean=mu,sd=sigma))
pnorm(1.645) - pnorm(-1.645)
pnorm(1.96) - pnorm(-1.96)
z <- seq(-3,3,by=0.001)
z.p <- dnorm(z)
plot(z,z.p,axes=F,type="l",
main="표준정규분포(95%)",ylab="",ylim=c(-0.04,0.4))
axis(1)
lines(c(-3,3),c(0,0))
points(-1.96,-0.02,pch=17,col="red")
text(-1.96,-0.035,"-1.96",col="red")
points(1.96,-0.02,pch=17,col="red")
text(1.96,-0.035,"1.96",col="red")
s <- seq(-1.96,1.96,by=0.001)
s.z <- dnorm(s,mean=0,sd=1)
s <- c(-1.96,s,1.96)
s.z <- c(0,s.z,0)
polygon(s,s.z,col="red",density=10,angle=305)
dbinom(7,size=10,prob=4/5)
pbinom(2,size=20,prob=0.05)
dbinom(7,size=10,prob=4/5)
1-pbinom(1,size=20,prob=0.2)
5/36
pnorm(750,mean=800,sd=40)
1-pnorm(20,mean=11,sd=4)
qnorm(0.9,mean=11,sd=4)
paste(100*(pnorm(90,mean=70,sd=8)-pnorm(80,mean=70,sd=8)),"%")
(pnorm(3,mean=1.5,sd=2)-pnorm(0,mean=1.5,sd=2))-(pnorm(2,mean=1.5,sd=2)-pnorm(1,mean=1.5,sd=2))
